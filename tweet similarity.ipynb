{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c2c67bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFAutoModel, AutoTokenizer\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "480a3fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('train.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bef2537",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "663b10da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2600, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b089611c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairs(dataset):\n",
    "    tweet_pairs = []\n",
    "    authors = dataset['user'].unique()\n",
    "\n",
    "    dic = {author: set() for author in authors}\n",
    "\n",
    "    total_pairs = len(dataset) // 2\n",
    "    for author in authors:\n",
    "\n",
    "        tweets_user = dataset[dataset['user'] == author]['text'].tolist()\n",
    "        same_author_pairs = min(len(tweets_user) * (len(tweets_user) - 1) // 2, total_pairs // 2)\n",
    "\n",
    "        sampled_indices_same = np.random.choice(len(tweets_user), size=(same_author_pairs, 2))\n",
    "        for i1, i2 in sampled_indices_same:\n",
    "\n",
    "\n",
    "            if (i1 not in dic[author]) and (i2 not in dic[author]):\n",
    "\n",
    "                tweet_pairs.append((tweets_user[i1], tweets_user[i2], author, author, 1))\n",
    "                dic[author].add(i1)\n",
    "                dic[author].add(i2)\n",
    "                total_pairs -= 1\n",
    "\n",
    "        diff_author_pairs = total_pairs // (len(authors) - 1)\n",
    "        for other_author in authors:\n",
    "            if other_author == author:\n",
    "                continue\n",
    "            tweets_by_other_author = dataset[dataset['user'] == other_author]['text'].tolist()\n",
    "\n",
    "            num_pairs_with_other_author = min(len(tweets_user) * len(tweets_by_other_author), diff_author_pairs)\n",
    "\n",
    "\n",
    "            sampled_indices_diff = np.random.choice(len(tweets_by_other_author), size=(num_pairs_with_other_author, 2))\n",
    "            for i1, i2 in sampled_indices_diff:\n",
    "                if (i1 not in dic[author]) and (i2 not in dic[other_author]):\n",
    "\n",
    "                    tweet_pairs.append((tweets_user[np.random.randint(len(tweets_user))], tweets_by_other_author[i1], author, other_author, 0))\n",
    "                    dic[author].add(i1)\n",
    "\n",
    "\n",
    "                    dic[other_author].add(i2)\n",
    "                    total_pairs -= 1\n",
    "\n",
    "        if total_pairs <= 0:\n",
    "            break\n",
    "\n",
    "    df = pd.DataFrame(tweet_pairs, columns=['text1', 'text2', 'u1', 'u2', 'isSimilar'])\n",
    "\n",
    "    return df\n",
    "\n",
    "NewDf =  pairs(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f19fe54c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text1</th>\n",
       "      <th>text2</th>\n",
       "      <th>u1</th>\n",
       "      <th>u2</th>\n",
       "      <th>isSimilar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Got my Mercurial Vapor IX for today's match. H...</td>\n",
       "      <td>I train fast to play fast. Thanks @niketrainin...</td>\n",
       "      <td>Cristiano</td>\n",
       "      <td>Cristiano</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What a night! A great result leads us one step...</td>\n",
       "      <td>pic.twitter.com/pXXUzVe1rQ</td>\n",
       "      <td>Cristiano</td>\n",
       "      <td>Cristiano</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You asked: Hi, i'm your fan #1 in Paris, can y...</td>\n",
       "      <td>We are excited to win the Copa del Rey today! ...</td>\n",
       "      <td>Cristiano</td>\n",
       "      <td>Cristiano</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Here's a sneak peek of the new @SacoorBrosME C...</td>\n",
       "      <td>Looking forward to meeting Almería on the pitc...</td>\n",
       "      <td>Cristiano</td>\n",
       "      <td>Cristiano</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Today I partner with @PestanaHotels for the co...</td>\n",
       "      <td>Hi everyone. Yesterday’s important win leads u...</td>\n",
       "      <td>Cristiano</td>\n",
       "      <td>Cristiano</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               text1  \\\n",
       "0  Got my Mercurial Vapor IX for today's match. H...   \n",
       "1  What a night! A great result leads us one step...   \n",
       "2  You asked: Hi, i'm your fan #1 in Paris, can y...   \n",
       "3  Here's a sneak peek of the new @SacoorBrosME C...   \n",
       "4  Today I partner with @PestanaHotels for the co...   \n",
       "\n",
       "                                               text2         u1         u2  \\\n",
       "0  I train fast to play fast. Thanks @niketrainin...  Cristiano  Cristiano   \n",
       "1                         pic.twitter.com/pXXUzVe1rQ  Cristiano  Cristiano   \n",
       "2  We are excited to win the Copa del Rey today! ...  Cristiano  Cristiano   \n",
       "3  Looking forward to meeting Almería on the pitc...  Cristiano  Cristiano   \n",
       "4  Hi everyone. Yesterday’s important win leads u...  Cristiano  Cristiano   \n",
       "\n",
       "   isSimilar  \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  \n",
       "3          1  \n",
       "4          1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NewDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e82e9768",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "class TweetSimilarityModel(torch.nn.Module):\n",
    "    def __init__(self, device):\n",
    "        super(TweetSimilarityModel, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased').to(device)\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        self.manhattan_distance = torch.nn.PairwiseDistance(p=1)  # Manhattan distance\n",
    "        self.classifier = torch.nn.Linear(self.bert.config.hidden_size * 2, 1).to(device)\n",
    "\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, text1, text2):\n",
    "        outputs1 = self.bert(**text1)\n",
    "        outputs2 = self.bert(**text2)\n",
    "\n",
    "    # Use the [CLS] token representation as the tweet's representation\n",
    "        tweet_rep1 = outputs1.last_hidden_state[:, 0, :]\n",
    "        tweet_rep2 = outputs2.last_hidden_state[:, 0, :]\n",
    "\n",
    "    # Feature extraction\n",
    "        tweet_rep_concat = torch.cat((tweet_rep1, tweet_rep2), dim=1)\n",
    "\n",
    "    # Calculate the Manhattan distance between the two tweet representations\n",
    "        manhattan_dist = self.manhattan_distance(tweet_rep1, tweet_rep2)\n",
    "\n",
    "    # Pass the concatenated tweet representations through a dense layer to get the similarity score\n",
    "        similarity_score = self.sigmoid(self.classifier(tweet_rep_concat))\n",
    "\n",
    "        return similarity_score, manhattan_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15c986b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = TweetSimilarityModel(device).to(device)\n",
    "model.eval()\n",
    "\n",
    "predicted_labels = []\n",
    "true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for index, row in NewDf.iterrows():\n",
    "        # Convert the pandas Series to strings\n",
    "        text1 = str(row['text1'])\n",
    "        text2 = str(row['text2'])\n",
    "\n",
    "        # Convert strings to tensors\n",
    "        text1 = model.tokenizer(text1, return_tensors='pt', padding=True, truncation=True, max_length=1500).to(device)\n",
    "        text2 = model.tokenizer(text2, return_tensors='pt', padding=True, truncation=True, max_length=1500).to(device)\n",
    "\n",
    "        # Get the similarity score and manhattan distance\n",
    "        similarity_score, _ = model(text1, text2)\n",
    "\n",
    "        # Round the similarity score to get the predicted label\n",
    "        predicted_label = torch.round(similarity_score.squeeze()).cpu().numpy()\n",
    "        predicted_labels.append(predicted_label)\n",
    "\n",
    "        # Append the true label\n",
    "        true_labels.append(row['isSimilar'])\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "predicted_labels = np.hstack(predicted_labels)\n",
    "true_labels = np.array(true_labels)\n",
    "\n",
    "# Calculate Precision, Recall, and F1 Score\n",
    "precision = precision_score(true_labels, predicted_labels)\n",
    "recall = recall_score(true_labels, predicted_labels)\n",
    "f1 = f1_score(true_labels, predicted_labels)\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "print(f\"Precision: {precision}, Recall: {recall}, F1 Score: {f1}, Accuracy : {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb19853",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
